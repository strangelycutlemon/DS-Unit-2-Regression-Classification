{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_regression_classification_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 3\n",
        "\n",
        "## Assignment\n",
        "\n",
        "We're going back to our other **New York City** real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices.\n",
        "\n",
        "But not just for condos in Tribeca...\n",
        "\n",
        "Instead, predict property sales prices for **One Family Dwellings** (`BUILDING_CLASS_CATEGORY` == `'01 ONE FAMILY DWELLINGS'`) using a subset of the data where the **sale price was more than \\\\$100 thousand and less than $2 million.** \n",
        "\n",
        "The [NYC Department of Finance](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page) has a glossary of property sales terms and NYC Building Class Code Descriptions. The data comes from the [NYC OpenData](https://data.cityofnewyork.us/browse?q=NYC%20calendar%20sales) portal.\n",
        "\n",
        "\n",
        "- [ ] Do train/test split. Use data from January — March 2019 to train. Use data from April 2019 to test.\n",
        "- [ ] Do exploratory visualizations with Seaborn.\n",
        "- [ ] Do one-hot encoding of categorical features.\n",
        "- [ ] Do feature selection with `SelectKBest`.\n",
        "- [ ] Fit a linear regression model with multiple features.\n",
        "- [ ] Get mean absolute error for the test set.\n",
        "- [ ] As always, commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Try [`RidgeCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) instead of Linear Regression, especially if your errors blow up! Watch [Aaron Gallant's 9 minute video on Ridge Regression](https://www.youtube.com/watch?v=XK5jkedy17w) to learn more.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Learn more about feature selection:\n",
        "    - [\"Permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "    - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "    - [mlxtend](http://rasbt.github.io/mlxtend/) library\n",
        "    - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n",
        "    - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n",
        "- [ ] Try [statsmodels](https://www.statsmodels.org/stable/index.html) if you’re interested in more inferential statistical approach to linear regression and feature selection, looking at p values and 95% confidence intervals for the coefficients.\n",
        "- [ ] Read [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way (without an excessive amount of formulas or academic pre-requisites).\n",
        "(That book is good regardless of whether your cultural worldview is inferential statistics or predictive machine learning)\n",
        "- [ ] Read Leo Breiman's paper, [\"Statistical Modeling: The Two Cultures\"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html):\n",
        "\n",
        "> Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
        "\n",
        "> - **Convenience and encapsulation.** You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
        "> - **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
        "> - **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipBYS77PUwNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "\n",
        "# Read New York City property sales data\n",
        "df = pd.read_csv('../data/NYC_Citywide_Rolling_Calendar_Sales.csv')\n",
        "\n",
        "# Change column names: replace spaces with underscores\n",
        "df.columns = [col.replace(' ', '_') for col in df]\n",
        "\n",
        "# SALE_PRICE was read as strings.\n",
        "# Remove symbols, convert to integer\n",
        "df['SALE_PRICE'] = (\n",
        "    df['SALE_PRICE']\n",
        "    .str.replace('$','')\n",
        "    .str.replace('-','')\n",
        "    .str.replace(',','')\n",
        "    .astype(int)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}